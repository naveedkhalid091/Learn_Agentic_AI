{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrusqOFzo1Y6jKGMC+tXr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(e)_Function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o1-VtoxJ5FVg"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "22ToFi_67Mjr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set up a model with tools:**\n",
        "\n",
        "This example uses 3 functions that control a simple hypothetical lighting system. Using these functions requires them to be called in a specific order. For example, you must turn the light system on before you can change color.\n",
        "\n",
        "While you can pass these directly to the model and let it try to call them correctly, specifying the function_calling_config gives you precise control over the functions that are available to the model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jj2rtPy57gjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_lights():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"  # telling to LLM regarding this function in tripple qutation.\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"   # telling to LLM regarding this function in tripple qutation.\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def stop_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"   # telling to LLM regarding this function in tripple qutation.\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights]\n",
        "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\",\n",
        "    tools=light_controls,  # Functions calling via tools\n",
        "    system_instruction=instruction\n",
        ")\n",
        "\n",
        "# Now your model is ready for function calling"
      ],
      "metadata": {
        "id": "JchOUYHS7fmo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=model.start_chat()"
      ],
      "metadata": {
        "id": "rXb1qAXa_92a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating a helper function:**\n",
        "\n",
        "- The helper function is to designed to make things easier for developers.\n",
        "- It takes simple, human friendly inputs ( Mode in str, & a list of allowed function names) & automatically converts those provided inputs into the detailed configuration format that Gemini API requires.\n",
        "- This abstraction helps developers avoid manual errors and speed up the process, ensuring the configuration is always correct.\n",
        "\n",
        "\n",
        "Developers after creation of this function only provide the `mode` and a list of allowed function names. The helper functions then automatically transforms these into the detailed structure the API requires.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eYuzH1LdF0nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function\n",
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "fW4ECovD7Dg4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Types of Modes:**\n",
        "\n",
        "The selection of modes is very important, the developer is basically delegating power to the LLM to use the functions based on the LLM's judgement.\n",
        "\n",
        "**1. `NONE`:** If you have provided the model with tools, but do not want to use those tools(functions) for the current conversational turn, then specify NONE as the mode. `NONE` tells the model not to make any function calls. The model will behave as `none` have been provided in the tools.\n",
        "\n",
        "**2. `Auto`:** When developer write the `Auto` mode it means that the developer is instructing the LLM to use only one function in the allowed list based on your best judgements.  \n",
        "\n",
        "**3. `Any`:** When developer write the `Any` mode it means that the developer is instructing the LLM to use any function (not be bound to a single function selection) in the allowed list."
      ],
      "metadata": {
        "id": "kMdkw9xxLvIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NONE mode:\n",
        "\n",
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hello light-bot, what can you do?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)\n",
        "\n"
      ],
      "metadata": {
        "id": "SA6lNUplLuks",
        "outputId": "e851fbb8-e959-4d79-ad08-ec17fa3fa489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, and I can set the color of the lights.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTO Mode\n",
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
        "print(response.parts)\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ],
      "metadata": {
        "id": "MLpSNOshMhqD",
        "outputId": "56e39da5-436f-4c1b-cd23-097299bc0a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[function_call {\n",
            "  name: \"enable_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Any Mode\n",
        "\n",
        "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ],
      "metadata": {
        "id": "-2fHrUlcNGK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Automatic function calling**"
      ],
      "metadata": {
        "id": "pfHGAfmYNrbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"enable_lights\", \"set_light_color\", \"stop_lights\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "auto_chat.send_message(\"It's awful dark in here- make it orange\", tool_config=tool_config)"
      ],
      "metadata": {
        "id": "Rv9zeZ6WNuSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting Brightness Function & color Temperature**\n",
        "\n",
        "This lighting control system lets you control the brightness of the light and it's color temperature, defined as two separate parameters:\n",
        " - **`brightness:`** Its data type will be in `number` & Light levels are from 0 to 100. Zero is off and 100 is full brightness.\n",
        " - **colorTemperature:** Its Data type will be `string` & colour temperature types will either be `daylight`, `cool` or `warm`.  "
      ],
      "metadata": {
        "id": "EzaPjAJqQixy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "def set_light_values(brightness:int , color_temp:Literal[\"daylight\", \"cool\", \"warm\"]):\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"brightness\": brightness,\n",
        "        \"colorTemperature\": color_temp\n",
        "    }\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "2mJERjTXSPc6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare function using model Initialization:"
      ],
      "metadata": {
        "id": "voAx9D2fWccq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",\n",
        "                                tools=[set_light_values])"
      ],
      "metadata": {
        "id": "mJ935EE1WzBr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_2=model_2.start_chat(enable_automatic_function_calling=True)\n",
        "response=chat_2.send_message(\"Dim the light so that the room feels cozy and warm\")\n",
        "\n",
        "response.text"
      ],
      "metadata": {
        "id": "L9--Hgt1XfRo",
        "outputId": "652f8524-7dcb-4da2-c490-80499704d57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OK. I've dimmed the lights to 30% brightness and set the color temperature to warm.  Let me know if you'd like to adjust it further.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parallel function calling**\n",
        "\n",
        "In addition to basic function calling described above, you can also call multiple functions in a single turn. This section shows an example for how you can use parallel function calling.\n",
        "\n"
      ],
      "metadata": {
        "id": "BbdVEp-Ef36d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function - 1 - Disco ball\n",
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "# function - 2 - Music On & Off\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "# function - 3 - Lights status\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "-p22yBkEgIee"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining all the above functions to runn parallel.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "# initializing model\n",
        "model_3 = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat_3 = model_3.start_chat()\n",
        "response = chat_3.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "id": "1bRxgaRUgrHI",
        "outputId": "fad7fb4e-f751-4d63-dd5c-61a113fb221d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power_disco_ball(power=True)\n",
            "start_music(loud=True, energetic=True, bpm=120.0)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    }
  ]
}