{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Td0lRXTE9/vbZMng86wA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/01_langchain_hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain\n",
        "\n",
        "Langchain is basically a framework or a wrapper which can connect any LLM at the back-end.\n",
        "\n",
        "In other words, Langchain is a framework designed to facilitate the development of applications using large language models (LLMs). It provides tools for chaining multiple LLMs and integrating them with external data sources, APIs, and services.\n"
      ],
      "metadata": {
        "id": "dp3czHhqqBcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benefits of using Langchain:\n",
        "\n",
        "\n",
        "Langchain reduces the cognitive load of learning and remembering different coding styles or commands for each LLM, which is a key benefit, other benefits are given below:\n",
        "\n",
        "\n",
        "1. **Works with Different Language Models:**\n",
        " - Langchain can connect to many different language models, so you can try out different ones or switch between them easily. This means you're not stuck with just one type of language model.\n",
        "\n",
        "2. **Chains Models Together:**\n",
        "\n",
        " - You can use Langchain to link multiple language models together, making them work together to solve a problem. This is useful when you need one model to do one thing, and another model to do something else.\n",
        "\n",
        "3. **Improves Performance:**\n",
        "\n",
        " - Langchain helps your applications run more smoothly and efficiently by managing how and when the language model is used. This can save time and reduce costs.\n",
        "\n",
        "4. **Easy for Developers:**\n",
        "\n",
        " - Langchain has an easy-to-use design, so developers can build applications faster and without too much hassle. It simplifies many of the hard parts of working with language models.\n",
        "\n",
        "5. **Support from the Community:**\n",
        "\n",
        " - Langchain has a helpful community of developers and plenty of guides, so if you run into problems, you can find answers or get advice easily. You can also add your own features to Langchain if needed.\n",
        "\n",
        "6. **Unified Interface:**\n",
        "\n",
        " - Langchain provides a consistent interface for working with multiple LLMs. This means you can focus on the logic of your application rather than worrying about the specific quirks of different LLM APIs.\n",
        "\n",
        "7. **Easy Switching Between Models:**\n",
        "\n",
        " - With Langchain, switching from one model to another (like OpenAI GPT to Gemini or others) can be done with minimal changes to your code. Instead of changing the way you interact with the model, you just need to adjust a few settings or configurations.\n",
        "\n"
      ],
      "metadata": {
        "id": "YJt-8KndroKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps of prompting from Langchain:\n",
        "\n",
        " - Steps involved in writting the first `Hello world` in the Langchain, are mentioned below:\n",
        "\n",
        "- However you can read the documentation of lanchain from the link: [LangChain Documentation](https://python.langchain.com/docs/introduction/)\n",
        "\n",
        "1. Install the Langchain and its SDK.\n",
        "2. Create API keys from the model you wanted to connect with.\n",
        "3. Give a nick/short name of your SDK installed at step one.\n",
        "4. import the API key.\n",
        "5. Use/ Initialize the SDK to import a class `ChatGoogleGenerativeAI` from Langchain's SDK.\n",
        "6. Define the Langchain `model` in a variable so that you may re-use that model.  \n",
        "7. Write a response with hello world using invoke method.\n",
        "8. print the response using print().   \n"
      ],
      "metadata": {
        "id": "emuPQwr-uTg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "3SA85bzQl1TZ"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain  # Installing Langchain to enable integration with large language models and extern"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain_google_genai # Installing Langchain SDK for seamless integration with Google GenAI models"
      ],
      "metadata": {
        "id": "3rhHrM5L28fq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_google_genai as genai # importing genai"
      ],
      "metadata": {
        "id": "HmroWA9nxP94"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "bKYRAyxc0x1N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "8D0NRfyf1tti"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(\n",
        "model=\"gemini-2.0-flash-exp\", # specify the model to use\n",
        "api_key=GOOGLE_API_KEY, # Provide the API key for Authentication\n",
        "temperature=0.3,  # set the randomness of the model's response\n",
        "max_output_tokens=1024,  # set the max token\n",
        " )"
      ],
      "metadata": {
        "id": "nH_Kiw3q2AcR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.invoke(\"What is the name of the capital of Pakistan\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJgKiANO5YbZ",
        "outputId": "45f60294-09cb-4a17-e681-8b807e2058c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Pakistan is **Islamabad**.\n"
          ]
        }
      ]
    }
  ]
}