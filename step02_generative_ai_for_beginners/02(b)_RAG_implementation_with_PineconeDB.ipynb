{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYbeMoKZ+xyS6i4EYGRhbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(b)_RAG_implementation_with_PineconeDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Implementation with PineConeDB:\n",
        "\n",
        "**Step#1:** Install the necessary environment as follows:  "
      ],
      "metadata": {
        "id": "vrhpEMw49_eN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1hRWYSN9vg2",
        "outputId": "d39c6719-a7ef-4931-bb45-7139f44de8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#2:** In this step we need a to initialize the Pinecone Database.\n",
        "\n",
        "So go to the Pinecone Database, create your account and Generate API key.    \n",
        "\n"
      ],
      "metadata": {
        "id": "cKwpoZGSA9mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import userdata\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "AX1G11huEmqf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step#3 - Create Indexing in the Pinecone Database:\n",
        "\n",
        "The below code can also be taken from the [PineCone Vector Database](https://www.pinecone.io/). First `Sign-in` and then go to the `Database -> Indexes` section.\n",
        "\n",
        "You can also see the below code in the [PineCone Documentation](https://python.langchain.com/docs/integrations/vectorstores/pinecone/) by scrolling down to the Initialization Section."
      ],
      "metadata": {
        "id": "7Xc0rpNxGE5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"online-rag-project\"  # change if desired\n",
        "\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768, # Replace with your model dimensions\n",
        "        metric=\"cosine\", # Replace with your model metric\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "ZflzyWF3G3J4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our Pinecone index is sucessfully setup, You can also varify this created Index (`online-rag-project`) into the PineCone Database and navigate to `Database -> Indexes`. After creating index, now all data will be stored in this `Index`.  \n",
        "\n",
        "\n",
        "Now, we need to select the embedding model as we had studied that the data can only be saved in vector form so we need to select the embedding model (which will convert our data into vectors/numbers).\n",
        "\n",
        "We will select the google embeddings model in our workings:\n",
        "\n",
        "You can find the Google embedding model from the below mentioned documentation.\n",
        "\n",
        "- [Google Embedding Documentation](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/).\n",
        "\n",
        "\n",
        "This these documentations It is clearly mentioned that you can Connect to Google's generative AI embeddings service using the `GoogleGenerativeAIEmbeddings` class, found in the `langchain-google-genai package` which we have installed at step # 1.\n",
        "\n",
        "But keep in your mind that You also need to get access of Gemini model for accessing the embedding model.\n",
        "\n",
        "So first access the Gemini model and then access the embeddings model as below:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4XSfvSLtNjUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY='GOOGLE_API_KEY'\n",
        "os.environ[GOOGLE_API_KEY]=userdata.get('GOOGLE_API_KEY')\n",
        "\n"
      ],
      "metadata": {
        "id": "dXIP_o1CUT9I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now embed the model as below:  \n",
        "\n",
        "\n",
        "\n",
        "**Note:** This below code is taken from [Google Embedding Documentation](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/), from the `usage` section."
      ],
      "metadata": {
        "id": "eOab0qElV50J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "print(vector[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijMyS2M-NpXO",
        "outputId": "74442e03-80fa-4b93-c288-c8d2fd240e09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05168594419956207, -0.030764883384108543, -0.03062233328819275, -0.02802734263241291, 0.01813093200325966]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now start from 44min"
      ],
      "metadata": {
        "id": "bR_mWXGcaKzp"
      }
    }
  ]
}