{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOZJtchVNpdVGy4y46XpuJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(b)_updated_RAG_implementation_with_PineconeDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation of RAG projects:**\n",
        "\n",
        "For RAG projects in langchain, you need to store and retreive your data.\n",
        "\n",
        "You need the **following environment** to set in your project.\n",
        "\n",
        "1. Install the langchain in your project for creating flexibility in switching the chat models.\n",
        "2. Firstly, you need a database for data storage and its access key.  \n",
        "3. An Embedding model for vectorization of your data.\n",
        "4. LLM model for conversations and its access key.\n",
        "\n",
        "Lets Install the above environment first."
      ],
      "metadata": {
        "id": "5JOE76agyfgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain"
      ],
      "metadata": {
        "id": "LpJ9k93a0lLw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain-pinecone"
      ],
      "metadata": {
        "id": "KolMKrKS05QZ",
        "outputId": "429cee6c-1ae0-43d1-bfa0-ff0bd678b245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/427.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain_google_genai"
      ],
      "metadata": {
        "id": "BYOfGO2CPzX4",
        "outputId": "9873cb2b-3b16-4824-deeb-96f7ab73d6d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gettting Access of `PINECONE` & `GEMINI` using API Keys:**"
      ],
      "metadata": {
        "id": "UFfzN7fEEafd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY') # Getting access of PINECONE Database\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY') # Getting access of Gemini"
      ],
      "metadata": {
        "id": "fjzbDljB1Vi3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialization of Pinecone client:**\n",
        "\n",
        "Initializing the `Pinecone client (pc)` is the important step as this client allows you to perform various operations such as creating indexes, inserting vectors, and executing queries."
      ],
      "metadata": {
        "id": "9jGtlFu9LiyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc=Pinecone()"
      ],
      "metadata": {
        "id": "oZCXiBixMIY1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create an Index in PINECONE using above client**."
      ],
      "metadata": {
        "id": "O6YT6TnZFEDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can optionally check the existing index name using be below code to prevent duplicates:**\n",
        "\n",
        "* **i)** First check if the index already exist with the same choosen name.\n",
        "\n",
        "* **ii)** Secondly create an index if the same name index is not already created."
      ],
      "metadata": {
        "id": "YCyVFXy9F1Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i) Checking the index name if it is already exist?\n",
        "\n",
        "existing_indexes=[]\n",
        "\n",
        "checking_db_indexes=pc.list_indexes()\n",
        "print(existing_indexes)\n",
        "\n",
        "for info_index in checking_db_indexes:\n",
        "  existing_indexes.append(info_index.name)\n",
        "\n",
        "print(existing_indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDotj3-qF01_",
        "outputId": "fc70bd27-66a6-4a70-c885-0b692115bd53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['online-rag-project', 'my-family', 'my-9th-chem-book', 'second-rag-project', 'family-structure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ii) Creation of Index\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "\n",
        "index_name=\"my-family\"\n",
        "\n",
        "if index_name in existing_indexes:\n",
        "  print(f\"Index {index_name} already exist\")\n",
        "else:\n",
        "  # PROCEED WITH INDEX CREATION\n",
        "  pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=786,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")"
      ],
      "metadata": {
        "id": "fBzpf3pZFXC4",
        "outputId": "1fbca07b-d90c-475b-ed8c-fa53b60fe708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index my-family already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accessing the above created Index:**\n",
        "\n",
        "- Accessing the index will help us inserting the vectors/embedded data through the below line."
      ],
      "metadata": {
        "id": "_VsIGzMuJsXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=pc.Index(index_name)"
      ],
      "metadata": {
        "id": "MuXSc6fgJvPL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** PINECONE database setup is successfully completed. Now you need to setup embedding model for vectorization and chunking of your data.\n",
        "\n",
        "You can also varify your created index into the PINECONE database by signing into your database and navigate to **`Database->Indexes`**.   "
      ],
      "metadata": {
        "id": "HqvgL-V1MuYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Select Embedding model:**\n",
        "\n",
        "This model will first ensure that all of your data has been vectorized (converted into numbers) and ready for entering into the Pinecone database through above **`index`** variable.\n",
        "\n",
        "The Embedding model can be selected/imported from the `langchain_google_genai` library as below:   "
      ],
      "metadata": {
        "id": "rGoUN-vfN9V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "E0TvFIU3PJUR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At this stage, the database is setup and embedding model is also selected for the vectorization of data, finally the vecotrized data will enter into the Pinecone database**\n",
        "\n",
        "The data that need to be vectorized consist of either simple `text`, `small file` or a `large file`.\n",
        "\n",
        "The **`simple text`** & **`small file`** will not be chunked but the **`large files`** will first went through the chunking process and then after chunking, the vectorization will be done.  \n",
        "\n",
        "Lets run all the possiblities one by one."
      ],
      "metadata": {
        "id": "DjpRNIPvM4Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import PineconeVectorStore**:\n",
        "\n",
        "- The **`PineconeVectorStore`** is a class of the LangChain framework that not only **embed your files automatically** before storing the files into vector databases but it also simplifies the process of `storing` and `retrieving` vector embeddings (the text of your file).  \n",
        "\n",
        "- However, you can **convert text into vectors** manually through the `embed_query` method as follow:\n",
        "\n",
        " `vector_text=embedding_model.embed_query(\"Hello, I am Naveed\")`\n",
        "  `print(vector_text)`\n",
        "\n",
        "But This manual effort has been eliminated by the vector store:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_snAgMxyYCw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "## create a vector store client\n",
        "vector_store=PineconeVectorStore(index=index, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "sH-frb38ZVo5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While:**\n",
        "- The `index` parameter tells the vector store where to store and retrieve the vector embeddings.\n",
        "- The embedding parameter defines how the textual data is converted into vectors."
      ],
      "metadata": {
        "id": "risW6_EMbUv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Prepare Documents for the upload**\n",
        "\n",
        " - Import the Document from `langchain_core.documents`.\n",
        " - Create a `Document` Object which contains the link of text/file you wanted to store into the Database.\n",
        " - Rather then writting the manual IDs for each document, you can import the `uuid` library for generating the random and unique IDs for each document.\n",
        "\n",
        "The relevent coding these steps is given below:    "
      ],
      "metadata": {
        "id": "2sV2p4Mc22Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1=Document(\n",
        "    page_content=\"Chemistry book\",\n",
        "    metadata={\"/content/Chemistry 10.pdf\":\"Chemistry Book\"} # path of the file and its title in dictionary\n",
        ")"
      ],
      "metadata": {
        "id": "NkUPRRlu4uy2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=\"/content/Chemistry 10.pdf\"  # making an object/variable to a file"
      ],
      "metadata": {
        "id": "7cQpBl8U94fV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "QaT749-49-9g",
        "outputId": "aa277fb6-d582-41f3-b311-e64a8ba15574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add document into Database"
      ],
      "metadata": {
        "id": "uA9AsxLh_BQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)\n"
      ],
      "metadata": {
        "id": "qFvLK39w7mSe",
        "outputId": "a59eda0d-85aa-4858-c001-7bd47ed59531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'page_content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c8489bd89f65>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muuids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muuids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
          ]
        }
      ]
    }
  ]
}