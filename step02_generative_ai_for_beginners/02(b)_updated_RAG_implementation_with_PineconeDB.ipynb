{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1B74KeZm4vnonjEI8fKJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(b)_updated_RAG_implementation_with_PineconeDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation of RAG projects:**\n",
        "\n",
        "For RAG projects in langchain, you need to store and retreive your data.\n",
        "\n",
        "You need the **following environment** to set in your project.\n",
        "\n",
        "1. Install the langchain in your project for creating flexibility in switching the chat models.\n",
        "2. Firstly, you need a database for data storage and its access key.  \n",
        "3. An Embedding model for vectorization of your data.\n",
        "4. LLM model for conversations and its access key.\n",
        "\n",
        "Lets Install the above environment first."
      ],
      "metadata": {
        "id": "5JOE76agyfgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain"
      ],
      "metadata": {
        "id": "LpJ9k93a0lLw",
        "outputId": "b9c9112f-443f-4c9f-adbf-4beb4159de4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/412.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain-pinecone"
      ],
      "metadata": {
        "id": "KolMKrKS05QZ",
        "outputId": "aac507b8-0ab1-4957-831e-dadd50e0a511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/427.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain_google_genai"
      ],
      "metadata": {
        "id": "BYOfGO2CPzX4",
        "outputId": "8219b651-c9fd-4282-d983-5d6339524aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gettting Access of `PINECONE` & `GEMINI` using API Keys:**"
      ],
      "metadata": {
        "id": "UFfzN7fEEafd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY') # Getting access of PINECONE Database\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY') # Getting access of Gemini"
      ],
      "metadata": {
        "id": "fjzbDljB1Vi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialization of Pinecone client:**\n",
        "\n",
        "Initializing the `Pinecone client (pc)` is the important step as this client allows you to perform various operations such as creating indexes, inserting vectors, and executing queries."
      ],
      "metadata": {
        "id": "9jGtlFu9LiyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc=Pinecone()"
      ],
      "metadata": {
        "id": "oZCXiBixMIY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create an Index in PINECONE using above client**."
      ],
      "metadata": {
        "id": "O6YT6TnZFEDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can optionally check the existing index name using be below code to prevent duplicates:**\n",
        "\n",
        "* **i)** First check if the index already exist with the same choosen name.\n",
        "\n",
        "* **ii)** Secondly create an index if the same name index is not already created."
      ],
      "metadata": {
        "id": "YCyVFXy9F1Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i) Checking the index name if it is already exist?\n",
        "\n",
        "existing_indexes=[]\n",
        "\n",
        "checking_db_indexes=pc.list_indexes()\n",
        "print(existing_indexes)\n",
        "\n",
        "for info_index in checking_db_indexes:\n",
        "  existing_indexes.append(info_index.name)\n",
        "\n",
        "print(existing_indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDotj3-qF01_",
        "outputId": "0c2fc50d-01a7-4da2-d401-21bb3dd9d43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['online-rag-project', 'my-books', 'my-9th-chem-book', 'second-rag-project', 'family-structure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ii) Creation of Index\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "\n",
        "index_name=\"my-books\"\n",
        "\n",
        "\n",
        "if index_name in existing_indexes:\n",
        "  print(f\"Index {index_name} already exist\")\n",
        "else:\n",
        "  # PROCEED WITH INDEX CREATION\n",
        "  pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")"
      ],
      "metadata": {
        "id": "fBzpf3pZFXC4",
        "outputId": "44229ce6-939a-49a7-82b3-ca8bc08d7d3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index my-books already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accessing the above created Index:**\n",
        "\n",
        "- Accessing the index will help us inserting the vectors/embedded data through the below line."
      ],
      "metadata": {
        "id": "_VsIGzMuJsXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=pc.Index(index_name)"
      ],
      "metadata": {
        "id": "MuXSc6fgJvPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** PINECONE database setup is successfully completed. Now you need to setup embedding model for vectorization and chunking of your data.\n",
        "\n",
        "You can also varify your created index into the PINECONE database by signing into your database and navigate to **`Database->Indexes`**.   "
      ],
      "metadata": {
        "id": "HqvgL-V1MuYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Select Embedding model:**\n",
        "\n",
        "This model will first ensure that all of your data has been vectorized (converted into numbers) and ready for entering into the Pinecone database through above **`index`** variable.\n",
        "\n",
        "The Embedding model can be selected/imported from the `langchain_google_genai` library as below:   "
      ],
      "metadata": {
        "id": "rGoUN-vfN9V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "E0TvFIU3PJUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At this stage, the database is setup and embedding model is also selected for the vectorization of data, finally the vecotrized data will enter into the Pinecone database**\n",
        "\n",
        "The data that need to be vectorized consist of either simple `text`, `small file` or a `large file`.\n",
        "\n",
        "The **`simple text`** & **`small file`** will not be chunked but the **`large files`** will first went through the chunking process and then after chunking, the vectorization will be done.  \n",
        "\n",
        "Lets run all the possiblities one by one."
      ],
      "metadata": {
        "id": "DjpRNIPvM4Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import PineconeVectorStore**:\n",
        "\n",
        "- The **`PineconeVectorStore`** is a class of the LangChain framework that not only **embed your files automatically** before storing the files into vector databases but it also simplifies the process of `storing` and `retrieving` vector embeddings (the text of your file).  \n",
        "\n",
        "- However, you can **convert text into vectors** manually through the `embed_query` method as follow:\n",
        "\n",
        " `vector_text=embedding_model.embed_query(\"Hello, I am Naveed\")`\n",
        "  `print(vector_text)`\n",
        "\n",
        "But This manual effort has been eliminated by the vector store:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_snAgMxyYCw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "## create a vector store client\n",
        "vector_store=PineconeVectorStore(index=index, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "sH-frb38ZVo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While:**\n",
        "- The `index` parameter tells the vector store where to store and retrieve the vector embeddings.\n",
        "- The embedding parameter defines how the textual data is converted into vectors."
      ],
      "metadata": {
        "id": "risW6_EMbUv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Prepare Documents for the upload**\n",
        "\n",
        "- **1.** If your document is small then follow below practice:\n",
        "\n",
        "  - Import the Document from `langchain_core.documents`.\n",
        "  - if you only wanted to upload \"texts\" or \"small document\" that don't need chunking then:\n",
        "    - Create a `Document` Object which contains the link of text/file you\n",
        "     wanted to store into the Database.\n",
        "    - Rather then writting the manual IDs for each document, you can import the `uuid` library for generating the random and unique IDs for each document.\n",
        "\n",
        "- **2.** If your file is **large and required chunking** then follow below steps:\n",
        "\n",
        "  - Import a library called `pymupdf4llm`, this library will convert your pdf file into a markdown file.\n",
        "  - Split the markdown file into smaller chunks by importing `MarkdownTextSplitter` from the `langchain.text_splitter`.\n",
        "  - Add the chunked document into database by attaching the random generated IDs through the `uuid` with documents.  \n",
        "\n",
        "The relevent coding these steps is given below:    "
      ],
      "metadata": {
        "id": "2sV2p4Mc22Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **If your document is `small` or `text only` then follow below practice**:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tKKhBs8ZhSNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# from langchain_core.documents import Document\n",
        "\n",
        "# document_1=Document(\n",
        "   # page_content=\"Chemistry book\",\n",
        "    # metadata={\"/content/Chemistry 10.pdf\":\"Chemistry Book\"} # path of the file and its title in dictionary\n",
        "# )\n",
        "\n",
        "\n",
        "# put all the ducments into an array because only array is accepted while adding the documents in below step\n",
        "# documents=[document_1]"
      ],
      "metadata": {
        "id": "NkUPRRlu4uy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add documents into Database\n",
        "\n",
        "# from uuid import uuid4\n",
        "\n",
        "# uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "# vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "id": "c_CiHMTlT_65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. If your file is large and required chunking then follow below steps:**"
      ],
      "metadata": {
        "id": "XRs8_UhYUPFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q pymupdf4llm"
      ],
      "metadata": {
        "id": "ZinEJQOPda_8",
        "outputId": "a2e30d1f-d68a-4833-98fb-abfd58fcce30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/20.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/20.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/20.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/20.0 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m17.0/20.0 MB\u001b[0m \u001b[31m172.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m172.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m172.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert PDF into markdown\n",
        "\n",
        "import pymupdf4llm\n",
        "\n",
        "pdf_path= \"/content/Chemistry 9.pdf\" # This book will be deleted automatically when colab session will terminate, so you need to upload it everytime\n",
        "md_text=pymupdf4llm.to_markdown(pdf_path)"
      ],
      "metadata": {
        "id": "IBZeebnDdrLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(md_text)"
      ],
      "metadata": {
        "id": "7MKPHVedUiOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split markdown text into Chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
        "                                          chunk_overlap=50,\n",
        "                                          separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "                                          )\n",
        "\n",
        "# Split the Markdown text into documents\n",
        "documents = splitter.create_documents([md_text])"
      ],
      "metadata": {
        "id": "z6JohDGyf5UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "QaT749-49-9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add document into Database after importing `uuid` library"
      ],
      "metadata": {
        "id": "uA9AsxLh_BQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "id": "qFvLK39w7mSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Querying from LLM regarding the document uploaded to the vector database**:\n",
        "\n",
        "We cannot directly ask the large language model (LLM) to get information from the vector database. Instead, we follow these steps:\n",
        " - 1. **Fetch Relevant Data from database:** First, we use a function called similarity_search to find the most relevant data from the vector database based on the user's query.\n",
        " - 2. **Combine Query and Data:** Next, we create a function that combines the user's query with the relevant data fetched from the database. This helps the LLM understand what information is needed.\n",
        " - 3. **Send to LLM:** Finally, we send the combined data (the query and the relevant database information) to the LLM. The LLM will then give a response based on this combined information.  \n",
        "\n",
        "This approach ensures that the LLM can respond accurately, using both the query and the relevant data retrieved from the database."
      ],
      "metadata": {
        "id": "gzcbmRrATxNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## similarity search\n",
        "\n",
        "query= \"units\"\n",
        "\n",
        "db_result=vector_store.similarity_search(\n",
        "    query,\n",
        "    k=10,\n",
        "    )\n",
        "\n",
        "for res in db_result:\n",
        "  print(f\"content:{res.page_content}\\nMetadata:{res.metadata}\\n\")"
      ],
      "metadata": {
        "id": "h2t58Tz0V-1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm calling\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.9,\n",
        "    max_tokens=1000,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "EDJ4bU5_X_xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function for final answer from LLM:"
      ],
      "metadata": {
        "id": "cf1u0BVkYUIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function\n",
        "def answer_to_user(query:str):\n",
        "  # Vector Search\n",
        "  vector_results = vector_store.similarity_search(query, k=2)\n",
        "  ## invoking llm\n",
        "  final_answer = llm.invoke (f'''Answer this user Query: {query}, Here are some ref to answer {vector_results}, ''')\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "IT72gTvcYd-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling function with query\n",
        "\n",
        "answer=answer_to_user(\"How many chapters are available in chemistry book? tell me the name along with chpater numbers\")\n",
        "print(answer.content)"
      ],
      "metadata": {
        "id": "ZLx4cVwTZIjF",
        "outputId": "786c35dd-0258-4162-e1a2-3a807ea7a949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 8 chapters in the chemistry book. Here are the chapter names and their corresponding numbers:\n",
            "\n",
            "*   **Unit 1:** Fundamentals of Chemistry\n",
            "*   **Unit 2:** Structure of Atoms\n",
            "*   **Unit 3:** Periodic Table and Periodicity of Properties\n",
            "*  **Unit 4:** Structure of Molecules\n",
            "*   **Unit 5:** Physical States of Matter\n",
            "*   **Unit 6:** Solutions\n",
            "*   **Unit 7:** Electrochemistry\n",
            "*   **Unit 8:** Chemical Reactivity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calling function with query\n",
        "\n",
        "answer=answer_to_user(\"make 10 multiple choice questions from chapter Fundamental of Chemistry? \")\n",
        "print(answer.content)"
      ],
      "metadata": {
        "id": "0SPupIZ2mXcT",
        "outputId": "d8a58a8c-4f63-4749-e089-b6b1e12778a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 10 multiple-choice questions based on the \"Fundamentals of Chemistry\" chapter, keeping in mind the provided document snippet focuses on the title of the chapter and doesn't provide specific content:\n",
            "\n",
            "**Instructions:** Choose the best answer for each question.\n",
            "\n",
            "**Questions:**\n",
            "\n",
            "1.  Which of the following is the study of matter and its properties, as well as how matter changes?\n",
            "    a) Physics\n",
            "    b) Biology\n",
            "    c) Chemistry\n",
            "    d) Geology\n",
            "\n",
            "2.  The basic unit of matter that cannot be further broken down by chemical means is a(n):\n",
            "    a) Molecule\n",
            "    b) Compound\n",
            "    c) Element\n",
            "    d) Mixture\n",
            "\n",
            "3.  Which of the following is NOT a state of matter?\n",
            "    a) Solid\n",
            "    b) Liquid\n",
            "    c) Gas\n",
            "    d) Energy\n",
            "\n",
            "4.  A substance made up of two or more elements chemically combined in a fixed ratio is a(n):\n",
            "    a) Mixture\n",
            "    b) Element\n",
            "    c) Compound\n",
            "    d) Solution\n",
            "\n",
            "5.  Which of the following is an example of a physical property?\n",
            "    a) Flammability\n",
            "    b) Reactivity\n",
            "    c) Density\n",
            "    d) Acidity\n",
            "\n",
            "6.  A change in which the composition of a substance is altered is called a:\n",
            "    a) Physical change\n",
            "    b) Chemical change\n",
            "    c) Phase change\n",
            "    d) State change\n",
            "\n",
            "7.  The smallest particle of a compound that can exist independently is a:\n",
            "    a) Atom\n",
            "    b) Ion\n",
            "    c) Molecule\n",
            "    d) Element\n",
            "\n",
            "8. Which of the following is an example of a mixture?\n",
            "    a) Water (H₂O)\n",
            "    b) Salt (NaCl)\n",
            "    c) Air\n",
            "    d) Gold (Au)\n",
            "    \n",
            "9. The method used to separate salt from saltwater is?\n",
            "    a) Filtration\n",
            "    b) Evaporation\n",
            "    c) Distillation\n",
            "    d) Decantation\n",
            "\n",
            "10. Which branch of chemistry deals with the composition and structure of matter?\n",
            "     a) Organic Chemistry\n",
            "     b) Analytical Chemistry\n",
            "     c) Physical Chemistry\n",
            "     d) Inorganic Chemistry\n",
            "\n",
            "**Answer Key:**\n",
            "\n",
            "1.  c) Chemistry\n",
            "2.  c) Element\n",
            "3.  d) Energy\n",
            "4.  c) Compound\n",
            "5.  c) Density\n",
            "6.  b) Chemical change\n",
            "7.  c) Molecule\n",
            "8.  c) Air\n",
            "9.  b) Evaporation\n",
            "10. b) Analytical Chemistry\n"
          ]
        }
      ]
    }
  ]
}