{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkpz3zLEqGHbIx78Y+qm4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/07(a)_Fine_Tuning_of_Gemini_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning of LLM using Gemini Model:\n",
        "\n",
        "Fine tuning is the process of taking a pre-trained model and further training it on a task-specific dataset to improve performance for specialized tasks. During \"Fine tuning” of a model we normally write examples of `inputs` and `desired outputs` to adjust the model's parameters.\n",
        "\n",
        "### Purpose of Fine-Tuning:\n",
        "\n",
        "It enables models to adapt to specific requirements that may not be fully addressed by general pre-training. For Gemini models, fine tuning ensures the model can better follow custom instructions or produce outputs tailored to your application.\n",
        "\n",
        "\n",
        "### Data Preparation:\n",
        "\n",
        "- **Dataset Structure:** The training dataset should consist of high-quality input–output pairs.\n",
        "- **Format Requirements:** Gemini models require examples to be in an input–output pair format (chat-style multi-turn conversations are not supported).\n",
        "- **Size & Quality:** You can start with as few as 20 examples, but typically 100–500 examples yield better results.\n",
        "\n",
        "### Model-Specific Considerations:\n",
        "\n",
        "For Gemini models (e.g., Gemini 1.5 Flash or Gemini 2.0):\n",
        "\n",
        "- **Input Limit:** Maximum input size is 40,000 characters.\n",
        "- **Output Limit:** Maximum output size is 5,000 characters.\n",
        "- **Tuning Environment:** Fine tuning can be executed through the Gemini API or using Google AI Studio, where you can manage your tuning jobs and monitor their status.\n",
        "\n",
        "### Training Process:\n",
        "1. **Developer's Role:**\n",
        " - **Data Preparation:** Developer create a set of example pairs—each with an input (what you ask) and an expected output (the correct answer). This forms the teaching material for the model.\n",
        " - **Setting Hyperparameters:** After importing or manually entering your input-output data in AI Studio, the developer sets certain hyperparameters. These hyperparameters guide the model on how to learn from the dataset. The key hyperparameters are:\n",
        "    - **Learning Rate:**  Developers set the learning rate from the UI of AI Studio, this determines how quickly the model adjusts its internal settings (parameters) A higher learning rate means the model makes larger adjustments, while a lower rate makes more gradual changes.\n",
        "    - **Batch Size:** Developers also set the Batch Size from the **AI Studio**, it determines that instead of processing your entire dataset at once, the model processes a small group of datasets.\n",
        "    For example, Think a batch size as like you are reading a book in diferent batches (days, hours or different times in a day) rather then to finish the complete book at once.  \n",
        "    - **Epochs:** An epoch is one complete pass through your entire dataset.Running multiple epochs means the model goes over the data several times, refining its performance with each pass. Like reading a book multiple times to fully understand the story—the more reads, the better your grasp, but keep in mind that when you will give maximum Epochs to the model then your model will be **overfit** because your model will now focus on `less reasoning/logic` and more   \n",
        "- **Feeding the Data:** The pre-trained Gemini model is given these examples. It \"reads\" the input and sees the correct output, learning what it should do when faced with similar inputs in the future.\n",
        "- **Parameter Adjustment:** The model compares its own response with the expected output. If there's a difference, it slightly adjusts its internal settings (parameters) automatically to reduce this error. This adjustment process is repeated each time it processes an example.\n",
        "- **Iterative Learning:**\n",
        "\n"
      ],
      "metadata": {
        "id": "lQA1AloZhY-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjlZHJF0hYMF"
      },
      "outputs": [],
      "source": []
    }
  ]
}