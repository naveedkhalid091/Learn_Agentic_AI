{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnQJgSPWXVSczfaY/oWFcc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(c)_Advance_RAG_Picture%26audio_recognition_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face & Audio Detection with Embeddings:**\n",
        "\n",
        "With introduction of this face detection technology, AI can now setup **security system** for not only Humans but also for the Animals as well.\n",
        "\n",
        "You can introduce Animal's Passport with the help of this technology becasue every animal has unique attributes from thier nose.   \n",
        "\n",
        "- You can install the **`facenet`** for face dedection.\n",
        "- You can also install the **`YAMNet`**  for voice/sound recognition.\n",
        "\n",
        "With the Introduction of above two technologies you can now ask LLM to make **written notes**  for you from a single video (Zoom Lecture) with the help of `facenet` & `YAMNet`. **`facenet`** will recognise the face from the video and YAMnet will regognise the voice of that person and LLM will produce written notes based on the wordings of your ZOOM class.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2xe7rCgfPDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1ug6y-cfHCp"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q pillow"
      ],
      "metadata": {
        "id": "CVlq4-L6hHwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # this is by defalut installed in colab files\n",
        "\n",
        "import torch.nn as nn  ## nn means neural network\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "FcVlIohWq3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1 # this is architecture\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model  # The complete architechture of this model is here now"
      ],
      "metadata": {
        "id": "QJEbJEHXrUPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Now if we will give any Human or animal piture to above model then that model will embedd the important features of the relevant face.**"
      ],
      "metadata": {
        "id": "nVnPt2X4sKtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing function to transform the Image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "  image=Image.open (image_path).convert('RGB')\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  return preprocess(image).unsqueeze(0)\n",
        "\n",
        "  # Function to create image embeddings\n",
        "\n",
        "  def create_image_embeddings(image_paths):\n",
        "    try:\n",
        "      input_tensor = preprocess_image(image_path)\n",
        "      with torch.no_grad():\n",
        "        embeddings = model(input_tensor) # embedding important line\n",
        "      return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "      print(\"Error:\",e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "JWdVv6FBsgSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images # Create images folder in directory"
      ],
      "metadata": {
        "id": "CzRW4_vEu-d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing pictures from url\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Download an image from URL and saves it to the \"image\" folder.\n",
        "\n",
        "  Agrs:\n",
        "  image_url: The url of thre image to download\n",
        "  image_name: The name of file to save the image as:\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path=os.path.join(\"images\",image_name)\n",
        "    response=requests.get(image_url, stream=True)\n",
        "    response.raise_for_status() # Raise exception for bad status codes:\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving image: {e}\")"
      ],
      "metadata": {
        "id": "zfUVfBDlx8nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://www.facebook.com/photo/?fbid=6506220269475611&set=a.187728274658207\", \"Khalid.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNtT3SQ0HVy",
        "outputId": "54ccaaa2-d7b9-45b4-e842-73421b9cbc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/Khalid.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "\n",
        "image_path2=\"/content/images/DSC06817.JPG\"\n",
        "abu=create_image_embeddings(image_path2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "1wd4EXqN1EGP",
        "outputId": "cb354a3f-7102-4a2a-9dc9-099307406d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'create_image_embeddings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4343d00e249a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_path2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/images/DSC06817.JPG\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mabu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_image_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'create_image_embeddings' is not defined"
          ]
        }
      ]
    }
  ]
}