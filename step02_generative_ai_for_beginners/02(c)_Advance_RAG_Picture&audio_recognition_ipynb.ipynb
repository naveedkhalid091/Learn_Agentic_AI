{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcHGqB2DSMcFTkS2AS71Q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step02_generative_ai_for_beginners/02(c)_Advance_RAG_Picture%26audio_recognition_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face & Audio Detection with Embeddings:**\n",
        "\n",
        "With introduction of this face detection technology, AI can now setup **security system** for not only Humans but also for the Animals as well.\n",
        "\n",
        "You can introduce Animal's Passport with the help of this technology becasue every animal has unique attributes from thier nose.   \n",
        "\n",
        "- You can install the **`facenet`** for face dedection.\n",
        "- You can also install the **`YAMNet`**  for voice/sound recognition.\n",
        "\n",
        "With the Introduction of above two technologies you can now ask LLM to make **written notes**  for you from a single video (Zoom Lecture) with the help of `facenet` & `YAMNet`. **`facenet`** will recognise the face from the video and YAMnet will regognise the voice of that person and LLM will produce written notes based on the wordings of your ZOOM class.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2xe7rCgfPDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q1ug6y-cfHCp"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q pillow"
      ],
      "metadata": {
        "id": "CVlq4-L6hHwF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # this is by defalut installed in colab files\n",
        "\n",
        "import torch.nn as nn  ## nn means neural network\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "FcVlIohWq3E9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1 # this is architecture\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model  # The complete architechture of this model is here now"
      ],
      "metadata": {
        "id": "QJEbJEHXrUPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Now if we will give any Human or animal piture to above model then that model will embedd the important features of the relevant face.**"
      ],
      "metadata": {
        "id": "nVnPt2X4sKtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing function to transform the Image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "  image=Image.open (image_path).convert('RGB')\n",
        "  preprocess = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  return preprocess(image).unsqueeze(0)"
      ],
      "metadata": {
        "id": "JWdVv6FBsgSf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create image embeddings\n",
        "\n",
        "def create_image_embeddings(image_path):\n",
        "  try:\n",
        "    input_tensor = preprocess_image(image_path)\n",
        "    with torch.no_grad():\n",
        "      embeddings = model(input_tensor) # embedding important line\n",
        "      return embeddings.squeeze().numpy()\n",
        "  except Exception as e:\n",
        "      print(\"Error:\",e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "TbPWzWN7JWAg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images # Create images folder in directory"
      ],
      "metadata": {
        "id": "CzRW4_vEu-d-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing pictures from url\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Download an image from URL and saves it to the \"image\" folder.\n",
        "\n",
        "  Agrs:\n",
        "  image_url: The url of thre image to download\n",
        "  image_name: The name of file to save the image as:\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path=os.path.join(\"images\",image_name)\n",
        "    response=requests.get(image_url, stream=True)\n",
        "    response.raise_for_status() # Raise exception for bad status codes:\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving image: {e}\")"
      ],
      "metadata": {
        "id": "zfUVfBDlx8nM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://www.facebook.com/photo/?fbid=6506220269475611&set=a.187728274658207\", \"Khalid.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNtT3SQ0HVy",
        "outputId": "76c52c36-8ac0-4c1f-b3ea-37d188faef3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/Khalid.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage/ create embedding of one picture\n",
        "\n",
        "image_path2=\"/content/images/Abu_1.JPG\"\n",
        "abu=create_image_embeddings(image_path2)\n",
        "\n",
        "print(\"Image embedding shape:\", abu.shape) # its lenght will be 512 which is determined through shape.\n",
        "print(\"Image Embedding:\",abu)"
      ],
      "metadata": {
        "id": "1wd4EXqN1EGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abu_1=create_image_embeddings(\"/content/images/Abu_1.JPG\")\n",
        "abu_2=create_image_embeddings(\"/content/images/Abu_3.jpg\")\n",
        "nav_1=create_image_embeddings(\"/content/images/Naveed_1.jpg\")\n",
        "nav_2=create_image_embeddings(\"/content/images/Naveed_2.jpg\")\n",
        "nav_3=create_image_embeddings(\"/content/images/Naveed_3.jpg\")"
      ],
      "metadata": {
        "id": "YDsShsMhNsQV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save all above image embeddings into `Milvus-lite` Database:**\n"
      ],
      "metadata": {
        "id": "iqjITHpOO6PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q milvus-lite"
      ],
      "metadata": {
        "id": "JmafqifFPHnr",
        "outputId": "585a0571-a9b3-491a-dd70-9a30db40d213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q pymilvus"
      ],
      "metadata": {
        "id": "qVEB6e3FPcwe",
        "outputId": "e6d835cd-f5b6-4339-d851-77b4bcd98b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "\n",
        "client=MilvusClient(\"./milvus_demo.db\")  # this will create a database in repository."
      ],
      "metadata": {
        "id": "3dp-uWSTPual"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"security_system\",\n",
        "    dimension=512 # dimension will be equals to the lenght of vectors.\n",
        ")"
      ],
      "metadata": {
        "id": "3WiP8uRqQmvm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[\n",
        "    {\"id\":1,\"person_name\":\"Khalid\",\"vector\":abu_1},\n",
        "    {\"id\":2,\"person_name\":\"Khalid\",\"vector\":abu_2},\n",
        "    {\"id\":3,\"person_name\":\"Naveed\",\"vector\":nav_1},\n",
        "    {\"id\":4,\"person_name\":\"Naveed\",\"vector\":nav_2},\n",
        "    {\"id\":5,\"person_name\":\"Naveed\",\"vector\":nav_3}\n",
        " ]"
      ],
      "metadata": {
        "id": "C0u58fQTRdXr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=client.insert(\n",
        "    collection_name=\"security_system\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "y0ietSF2Wxa2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=client.search(\n",
        "    collection_name=\"security_system\",\n",
        "    data=[abu_1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\",\"person_name\"]\n",
        ")\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "id": "okiasVn5XQ7f",
        "outputId": "33969141-8f53-47eb-eda9-0068902c0a02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 1.0, 'entity': {'person_name': 'Khalid', 'id': 1}}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload a different Pic and ask the model to search about the person in your database.  "
      ],
      "metadata": {
        "id": "7jhztrwEYCLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload a different picture & create its embeddings\n",
        "\n",
        "abu_3=create_image_embeddings(\"/content/images/abu_4.jpg\")"
      ],
      "metadata": {
        "id": "gMOGrVDkYS_m"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=client.search(\n",
        "    collection_name=\"security_system\",\n",
        "    data=[abu_3],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\",\"person_name\"]\n",
        ")\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "id": "6HnU5ZiFZEdF",
        "outputId": "0fd4a2d9-b5e0-49de-f9af-8d997511a3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 2, 'distance': 0.6875054836273193, 'entity': {'person_name': 'Khalid', 'id': 2}}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: You have now uploaded a different picture of a person and the AI model is recognized him from its database.\n",
        "You can now create a security system based on your database, like Nadra system.**\n",
        ""
      ],
      "metadata": {
        "id": "FRTbUaM-ZLGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recognizing voice of a person using `YAMnet`.**\n"
      ],
      "metadata": {
        "id": "ZyGZPxD7aZ2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the YAMnet for voice recognition and the code will be same.\n",
        "\n",
        "All the code is available in below link:  \n",
        "\n",
        "[Sir Qasim Repo](https://github.com/EnggQasim/5_days_AI_Agents_Training/blob/main/03_Image_Sound_RAG_Ollama_fastapi/03_voice_embedding.ipynb)"
      ],
      "metadata": {
        "id": "H9kiJXrvamav"
      }
    }
  ]
}