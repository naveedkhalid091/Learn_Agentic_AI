{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSaQ2O429iIQ5kSUer+QzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveedkhalid091/Learn_Agentic_AI/blob/main/step00_hello_world/00_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hello World AI API: **\n",
        "\n",
        "In the context of interacting with Large Language Models (LLMs), the terms \"prompting\" and \"completion\" describe the two main stages of communication:  \n",
        "\n",
        "**Prompting:** This is the input phase where a user provides an instruction or query to the LLM.\n",
        "\n",
        "**Completion:** This is the output phase where the LLM generates a response based on the given prompt.\n",
        "\n",
        "# **Calling LLM through a Web Interface or Making a API Call:**\n",
        "\n",
        "The concepts of \"prompting\" and \"completion\" apply both when interacting with a Large Language Model (LLM) through a web interface and when making API calls. Here's how these processes function in each context:\n",
        "\n",
        "\n",
        "\n",
        "# 1.  Web Interface Interaction:\n",
        "\n",
        "* **Prompting:** When you use a web interface to interact with an LLM, you typically enter your input or query into a text box. This input serves as the prompt, guiding the model on the task you want it to perform.\n",
        "\n",
        "* **Completion:** After submitting your prompt, the LLM processes it and generates a response, which is then displayed on the web page. This response is the completion, fulfilling the request made by your prompt.\n",
        "\n",
        "\n",
        "# 2.   API Interaction:\n",
        "\n",
        "  *   **Prompting:** When interacting with an LLM via an API, your application sends a request to the model's endpoint. This request includes the prompt, which is the input text or instruction you want the model to process.\n",
        "\n",
        "  *   **Completion:** The LLM processes the prompt and returns a response to your application. This response, known as the completion, contains the model's generated text based on the input prompt.\n",
        "\n",
        "In both scenarios, the **prompt** is the input that directs the LLM's behavior, and the **completion** is the output generated by the model in response to that input.\n",
        "\n",
        "Understanding this interaction is crucial for effectively utilizing LLMs across different platforms and applications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NH2G5L3VeLcx"
      }
    }
  ]
}
